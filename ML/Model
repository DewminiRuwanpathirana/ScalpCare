import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
from keras.models import load_model

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
from keras.models import load_model


train_path = '/content/drive/MyDrive/DataSet/train'
test_path = '/content/drive/MyDrive/DataSet/test'
val_path = '/content/drive/MyDrive/DataSet/val'

# Define image size and batch size
img_size = (224, 224)
batch_size = 32


# Define data generators for training, validation, and testing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # Split the training data into training and validation sets
)


train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

model = keras.Sequential(
    [
        # First convolutional layer
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(img_size[0], img_size[1], 3)),
        layers.MaxPooling2D(pool_size=(2, 2)),
        
        # Second convolutional layer
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        
        # Third convolutional layer
        layers.Conv2D(128, (3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        
        # Flatten the output from the convolutional layers
        layers.Flatten(),
        
        # Fully connected layers
        layers.Dense(64, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)


# Print a summary of the model architecture
model.summary()

model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

epochs = 5

history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=val_generator
)

test_loss, test_acc = model.evaluate(test_generator)

print(f"Test loss: {test_loss}")
print(f"Test accuracy: {test_acc}")

model.save('/content/drive/MyDrive/SCmodel.h5')
print("Model Saved as : ScalpCareModel-Final.h5")

import json
np.save('my_history.npy',history.history)
import pandas as pd

# convert the history.history dict to a pandas DataFrame:     
hist_df = pd.DataFrame(history.history) 

# save to json:  
hist_json_file = 'history.json' 
with open(hist_json_file, mode='w') as f:
    hist_df.to_json(f)

# or save to csv: 
hist_csv_file = 'history.csv'
with open(hist_csv_file, mode='w') as f:
    hist_df.to_csv(f)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'],color='red',label='train')
plt.plot(history.history['val_accuracy'],color='blue',label='validation')
plt.legend()
plt.show()

plt.plot(history.history['loss'],color='red', label = 'train_loss')
plt.plot(history.history['val_loss'],color='blue', label = 'val_loss')
plt.legend()
plt.show()

class_names = {
    0: 'Alopecia Areata',
    1: 'Contact Dermatitis',
    2: 'Folliculitis',
    3: 'Head Lice',
    4: 'Lichen Planus',
    5: 'Male pattern Baldness',
    6: 'Psoriasis',
    7: 'Seborrheic Dermatitis',
    8: 'Telogen Effluvium',
    9: 'Tinea Capitis',
}

from keras import models

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Load the pre-trained CNN model
model = models.load_model('/content/drive/MyDrive/SCmodel.h5')

# Load the test image
img = tf.io.read_file('https://images.ctfassets.net/j6utfne5ne6b/2CymBRddLBVKYWFN8bTTIz/ab36c5e05e74230fb82a9e0b880cc316/Yellow_dandruff_on_scalp.jpg?fm=webp&q=75')
img = tf.image.decode_image(img, channels=3, expand_animations=False)
interpolation = "bilinear"
interpolation = image_utils.get_interpolation(interpolation)
img = tf.image.resize(img,(224, 224), method=interpolation)
img = np.expand_dims(img, axis=0)
img = img * 1/255.0

# Make predictions on the test image
preds = model.predict(img)

#print the predicted class label
class_label = np.argmax(preds)
print('Predicted class label:', class_label)

# Get the predicted class name.
class_name = class_names[class_label]
print('Predicted class name: ', class_name)
img.shape
